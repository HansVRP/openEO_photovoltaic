{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae568901",
   "metadata": {},
   "source": [
    "# Inference with the model on openEO\n",
    "\n",
    "This notebook demonstrates how to use a trained model for inference with onnxruntime in an udf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd8fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "# Make the connection and authenticate\n",
    "import openeo\n",
    "\n",
    "#Choose preferred backend\n",
    "#conn = openeo.connect(\"https://openeo.vito.be/openeo/\").authenticate_oidc()\n",
    "conn = openeo.connect(\"https://openeo.dataspace.copernicus.eu/\").authenticate_oidc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7cb3d",
   "metadata": {},
   "source": [
    "A workflow for processing Sentinel-2 Level-2A earth observation data using openEO in orden to obtain the desired data, compatible with the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be278dd3-b961-4340-a41b-bdc6ca6a4227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary utility function\n",
    "from utils import  timesteps_as_bands\n",
    "\n",
    "# Load Sentinel-2 Level-2A data cube\n",
    "s2_cube = conn.load_collection(\n",
    "                collection_id = \"SENTINEL2_L2A\",\n",
    "                spatial_extent = \n",
    "                {\"west\": 12.17,\n",
    "                  \"east\": 12.18,\n",
    "                  \"south\": 51.46,\n",
    "                  \"north\": 51.47},\n",
    "                temporal_extent = [\"2022-01-01\",\"2022-12-31\"],\n",
    "                bands = [\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B11\",\"B12\",\"SCL\"],\n",
    "                properties = {\"eo:cloud_cover\": lambda x: x.lte(65)}\n",
    ")\n",
    "\n",
    "\n",
    "# Create weekly composites by taking the mean\n",
    "s2_cube = s2_cube.process(\"mask_scl_dilation\", data=s2_cube, scl_band_name=\"SCL\").filter_bands(s2_cube.metadata.band_names[:-1])\n",
    "\n",
    "# Create weekly composites by taking the mean\n",
    "s2_cube = s2_cube.aggregate_temporal_period(\n",
    "    period = \"week\",\n",
    "    reducer = \"mean\"\n",
    ")\n",
    "\n",
    "# Fill gaps in the data using linear interpolation\n",
    "s2_cube = s2_cube.apply_dimension(\n",
    "    dimension = \"t\",\n",
    "    process = \"array_interpolate_linear\"\n",
    ")\n",
    "\n",
    "# Filter out January and December data to ensure 43 weeks of data\n",
    "s2_cube = s2_cube.filter_temporal([\"2022-02-01\",\"2022-11-30\"]) # This should result in 43 weeks\n",
    "\n",
    "# Rearrange cube from (time, x, y bands) to (x, y, time*bands)\n",
    "s2_cube = timesteps_as_bands(s2_cube, 43)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d7f93",
   "metadata": {},
   "source": [
    "Load in the model from the vito artifactory and the required dependencies and excecute the prediction job. The output is stored as a netCDF in the local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f6a55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-24040344e1094fcebe12423d94038077': send 'start'\n",
      "0:00:17 Job 'j-24040344e1094fcebe12423d94038077': created (progress N/A)\n",
      "0:00:22 Job 'j-24040344e1094fcebe12423d94038077': created (progress N/A)\n",
      "0:00:29 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:00:39 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:00:49 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:01:02 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:01:17 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:01:37 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:02:01 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:02:31 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:03:08 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:03:55 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:04:54 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:05:54 Job 'j-24040344e1094fcebe12423d94038077': running (progress N/A)\n",
      "0:06:54 Job 'j-24040344e1094fcebe12423d94038077': error (progress N/A)\n",
      "Your batch job 'j-24040344e1094fcebe12423d94038077' failed. Error logs:\n",
      "[{'id': '[1712140361709, 603252]', 'time': '2024-04-03T10:32:41.709Z', 'level': 'error', 'message': 'Error communicating with MapOutputTracker'}, {'id': '[1712140449437, 585158]', 'time': '2024-04-03T10:34:09.437Z', 'level': 'error', 'message': 'Task 0 in stage 10.0 failed 4 times; aborting job'}, {'id': '[1712140451385, 720502]', 'time': '2024-04-03T10:34:11.385Z', 'level': 'error', 'message': 'OpenEO batch job failed: UDF Exception during Spark execution:   File \"/opt/openeo/lib/python3.8/site-packages/openeo/udf/run_code.py\", line 149, in run_udf_code\\n    module = load_module_from_string(code)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeo/udf/run_code.py\", line 60, in load_module_from_string\\n    exec(code, globals)\\n  File \"<string>\", line 13, in <module>\\nNameError: name \\'functools\\' is not defined'}]\n",
      "Full logs can be inspected in an openEO (web) editor or with `connection.job('j-24040344e1094fcebe12423d94038077').logs()`.\n"
     ]
    },
    {
     "ename": "JobFailedException",
     "evalue": "Batch job 'j-24040344e1094fcebe12423d94038077' didn't finish successfully. Status: error (after 0:07:08).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJobFailedException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Reduce the bands dimesnion to a single prediction using the udf\u001b[39;00m\n\u001b[0;32m     20\u001b[0m prediction \u001b[38;5;241m=\u001b[39m s2_cube\u001b[38;5;241m.\u001b[39mreduce_bands(reducer\u001b[38;5;241m=\u001b[39mudf)\n\u001b[1;32m---> 22\u001b[0m prediction_job \u001b[38;5;241m=\u001b[39m \u001b[43mprediction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./photovoltaic_prediction.nc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphotovoltaic_prediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VROMPAYH\\AppData\\Local\\anaconda3\\envs\\pv_openeo\\lib\\site-packages\\openeo\\rest\\datacube.py:2227\u001b[0m, in \u001b[0;36mDataCube.execute_batch\u001b[1;34m(self, outputfile, out_format, print, max_poll_interval, connection_retry_interval, job_options, validate, **format_options)\u001b[0m\n\u001b[0;32m   2224\u001b[0m     out_format \u001b[38;5;241m=\u001b[39m guess_format(outputfile)\n\u001b[0;32m   2226\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_job(out_format\u001b[38;5;241m=\u001b[39mout_format, job_options\u001b[38;5;241m=\u001b[39mjob_options, validate\u001b[38;5;241m=\u001b[39mvalidate, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_options)\n\u001b[1;32m-> 2227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_synchronous\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2228\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2229\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_poll_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_poll_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_retry_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_retry_interval\u001b[49m\n\u001b[0;32m   2230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VROMPAYH\\AppData\\Local\\anaconda3\\envs\\pv_openeo\\lib\\site-packages\\openeo\\rest\\job.py:239\u001b[0m, in \u001b[0;36mBatchJob.run_synchronous\u001b[1;34m(self, outputfile, print, max_poll_interval, connection_retry_interval)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_synchronous\u001b[39m(\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28mself\u001b[39m, outputfile: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;28mprint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mprint\u001b[39m, max_poll_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, connection_retry_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[0;32m    237\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchJob:\n\u001b[0;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Start the job, wait for it to finish and download result\"\"\"\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_and_wait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_poll_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_poll_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_retry_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_retry_interval\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m# TODO #135 support multi file result sets too?\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outputfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\VROMPAYH\\AppData\\Local\\anaconda3\\envs\\pv_openeo\\lib\\site-packages\\openeo\\rest\\job.py:321\u001b[0m, in \u001b[0;36mBatchJob.start_and_wait\u001b[1;34m(self, print, max_poll_interval, connection_retry_interval, soft_error_max)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogs(level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mERROR))\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull logs can be inspected in an openEO (web) editor or with `connection.job(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m).logs()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m     )\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JobFailedException(\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt finish successfully. Status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    323\u001b[0m         job\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mJobFailedException\u001b[0m: Batch job 'j-24040344e1094fcebe12423d94038077' didn't finish successfully. Status: error (after 0:07:08)."
     ]
    }
   ],
   "source": [
    "\n",
    "# Supply the model as a URL. The model is stored in artifactory\n",
    "model_url = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/photovoltaic/random_forest.onnx\"\n",
    "udf = openeo.UDF.from_file(\n",
    "    \"udf_rf_onnx.py\", \n",
    "    context={\n",
    "        \"model_url\": model_url\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the onnx dependencies to the job options. You can reuse this existing dependencies archive\n",
    "dependencies_url = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/openeo/onnx_dependencies_1.16.3.zip\"\n",
    "job_options = {\n",
    "    \"udf-dependency-archives\": [\n",
    "        f\"{dependencies_url}#onnx_deps\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Reduce the bands dimesnion to a single prediction using the udf\n",
    "prediction = s2_cube.reduce_bands(reducer=udf)\n",
    "\n",
    "prediction_job = prediction.execute_batch(\n",
    "    \"./photovoltaic_prediction.nc\",\n",
    "    job_options=job_options,\n",
    "    title=\"photovoltaic_prediction\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
